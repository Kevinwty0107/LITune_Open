<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="LITune: A New Paradigm in Tuning Learned Indexes with Reinforcement Learning.">
  <meta property="og:title" content="LITune: A New Paradigm in Tuning Learned Indexes with Reinforcement Learning"/>
  <meta property="og:description" content="Learn about LITune, a reinforcement learning enhanced approach for tuning learned indexes."/>
  <meta property="og:url" content="https://RL4Sys.github.io/LITune"/>
  <!-- <meta property="og:image" content="static/images/litune_banner.png" /> -->
  <meta name="twitter:title" content="LITune-A New Paradigm in Tuning Learned Indexes: A Reinforcement Learning Enhanced Approach">
  <meta name="twitter:description" content="Discover LITune, a safe and adaptive RL-based system for tuning learned indexes.">
  <!-- <meta name="twitter:image" content="static/images/litune_twitter_banner.png"> -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="LITune, learned indexes, reinforcement learning, indexing, database systems">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>LITune: A New Paradigm in Tuning Learned Indexes</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <!-- (Optional) Additional styling for the new hero -->
  <style>
    .hero-body {
      padding-top: 4rem;
      padding-bottom: 4rem;
    }
    .subtitle-authors {
      margin-top: 1rem;
      margin-bottom: 2rem;
      line-height: 1.5;
    }
  </style>
</head>
<body>

<!-- New Hero Section: Title, Authors, and Buttons -->
<section class="hero is-light" style="padding-top: 2rem; padding-bottom: 2rem;">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title is-2">
        LITune: A New Paradigm in Tuning Learned Indexes: <br>
        A Reinforcement Learning Enhanced Approach
      </h1>
      <p class="subtitle is-5 subtitle-authors">
        Taiyi Wang<sup>1</sup>, Liang Liang<sup>2</sup>, Guang Yang<sup>3</sup>, Thomas Heinis<sup>3</sup>,<br>
        and Eiko Yoneki<sup>1*</sup><br>
        <span style="font-size: 0.9em;">
          <sup>1</sup> University of Cambridge <br>
          <sup>2</sup> EPFL <br>
          <sup>3</sup> Imperial College London<br>
          <em>* Corresponding author: eiko.yoneki@cl.cam.ac.uk</em>
        </span>
      </p>
      <div class="buttons is-centered">
        <a href="static/pdfs/LITune_Paper.pdf" class="button is-primary is-rounded" target="_blank">
          <span class="icon"><i class="fas fa-file-pdf"></i></span>
          <span>Paper</span>
        </a>
        <a href="https://github.com/SubAnony/LITune_SIGMOD_25/" class="button is-link is-rounded" target="_blank">
          <span class="icon"><i class="fab fa-github"></i></span>
          <span>Code</span>
        </a>
        <a href="https://www.arxiv.org/abs/2502.05001" class="button is-dark is-rounded" target="_blank">
          <span class="icon"><i class="ai ai-arxiv"></i></span>
          <span>arXiv</span>
        </a>
      </div>
    </div>
  </div>
</section>
<!-- End Hero Section -->

<!-- Demo Video Section (directly below the title) -->
<section class="section is-light" style="padding-top: 1rem; padding-bottom: 1rem;">
  <div class="container has-text-centered">
    <h4 class="subtitle is-5">Demo Video of LITune Tuning Process</h4>
    <video controls muted width="80%">
      <source src="static/videos/demo.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>
</section>
<!-- End Demo Video Section -->

<!-- ABSTRACT -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Abstract</h2>
    <div class="content has-text-justified">
      <p>
        Learned Index Structures (LIS) have significantly advanced data management by leveraging machine learning models to 
        optimize data indexing. However, designing these structures often involves critical trade-offs, making it challenging 
        for both designers and end-users to find an optimal balance tailored to specific workloads and scenarios. While some indexes 
        offer adjustable parameters that demand intensive manual tuning, others rely on fixed configurations based on heuristic 
        auto-tuners or expert knowledge, which may not consistently deliver optimal performance. This paper introduces LITune, 
        a novel framework for end-to-end automatic tuning of Learned Index Structures. LITune employs an adaptive training pipeline equipped with 
        a tailor-made Deep Reinforcement Learning (DRL) approach to ensure stable and efficient tuning. To accommodate long-term dynamics arising 
        from online tuning, we further enhance LITune with an on-the-fly updating mechanism termed the O2 system. These innovations allow LITune 
        to effectively capture state transitions in online tuning scenarios and dynamically adjust to changing data distributions and workloads, 
        marking a significant improvement over other tuning methods. Our experimental results demonstrate that LITune achieves up to a 98% reduction 
        in runtime and a 17-fold increase in throughput compared to default parameter settings given a selected Learned Index instance. 
        These findings highlight LITune's effectiveness and its potential to facilitate broader adoption of LIS in real-world applications.
      </p>
    </div>
  </div>
</section>


<!-- SECTION 1: Observation and Summary -->
<section class="section is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3">1. Observation and Summary of Our Work</h2>

    <div class="content has-text-justified">
      <p>
        The intersection of data management and machine learning has given rise to learned index
        structures. These indexes integrate machine learning, replacing traditional algorithmic
        components, to capture data distributions and optimize search times. Notable examples include
        RMI [1], ALEX [2], and PGM [3], which have become
        subjects of extensive research.
      </p>
      <p>
        The effective design of a learned index involves deliberate trade-offs to achieve optimal
        performance for varying workloads. For instance, ALEX favors combined search and update
        performance by introducing gaps at the expense of space efficiency [ding2020alex]. On the
        other hand, the dynamic PGM Index prioritizes update efficiency over search performance
        [3]. These design trade-offs lead to more complex structures with configurable
        parameters. Tuning these parameters is the key to balancing trade-offs that ensure higher
        performance over traditional indexes.
      </p>
      <p>
        Beyond the primary parameters, learned indexes like ALEX have more subtle tunable factors
        that are often overlooked for simplicity. These parameters affect various aspects of the
        index performance, from operation cost to the structure of the index. Adjusting them in
        real-world scenarios can lead to substantial performance improvements, though it requires
        a more complex tuning process.
      </p>
    </div>

    <!-- Figure 1 (obs1) -->
    <figure class="image" style="margin-top: 20px;">
      <img src="static/images/ob1.png" alt="Figure 1: Combined performance surfaces and speedups.">
      <figcaption style="margin-top: 10px; text-align:center;">
        <strong>Figure 1.</strong> (a) shows the performance surface of a learned index (ALEX)
        under wild exploration of the parameter space. (b) highlights the optimal performance
        speedup achieved by LITune compared to default expert-selected parameters. (c) illustrates
        the continuous tuning performance of our system alongside other out-of-the-box methods under
        default configurations. (d) compares the tuning stability and costs across methods to reach
        their respective optimal performance levels.
      </figcaption>
    </figure>

    <div class="content has-text-justified" style="margin-top: 20px;">
      <p>
        Selecting the right tuning approach for learned indexes involves navigating a myriad of
        parameter configurations. In practice, parameterized indexes can exhibit vastly different
        performance due to parameter choices (see Figure 1(a)). This variability underscores the
        complexities and potential performance swings when considering the full spectrum of
        high-dimensional and continuous parameter configurations. Moreover, unlike algorithmic
        indexes such as B+trees that perform well out of the box, learned indexes are
        distribution-dependent and typically lack automatic tuning resources. Thus, a high-quality
        tuner is necessary to identify optimal solutions within a limited budget.
      </p>
    </div>

    <!-- Figure 2 (obs2) -->
    <figure class="image" style="margin-top: 20px;">
      <img src="static/images/ob2.png" alt="Figure 2: Parameter value distributions and impact scores.">
      <figcaption style="margin-top: 10px; text-align:center;">
        <strong>Figure 2.</strong> Selected parameter value distributions and their impact scores
        across different workloads when tuning on ALEX. Heatmap colors represent normalized optimal
        parameter values, while percentages indicate each parameter's individual tuning impact.
      </figcaption>
    </figure>

    <div class="content has-text-justified" style="margin-top: 20px;">
      <p>
        By fine-tuning these parameters, we can achieve significant performance improvements.
        Figure 1(b) emphasizes the substantial performance gains (measured by query runtime speedup)
        achieved by our tuning system over the SOSD dataset. Moreover, real-world usage often involves
        dynamic workloads, as illustrated in Figure 1(c), underscoring the need for adaptive tuning.
        Another challenge is safe tuning. Aggressive parameter exploration can lead to system
        instability, as shown in Figure 1(d). These observations highlight the necessity of a
        tailor-made tuning system like <strong>LITune</strong> rather than relying on out-of-box
        methods.
      </p>
    </div>
  </div>
</section>

<!-- SECTION 2: LITune System -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">2. <span style="text-transform:none;">LITune</span> System</h2>
    <br>

    <h3 class="subtitle is-4">2.1 Motivation</h3>
    <div class="content has-text-justified">
      <p>
        Unlike existing index tuning works that concentrate on a limited set of observable parameters,
        our work tackles the more complex challenge of tuning within a vast parameter space where
        parameters interact in non-independent ways. This complexity demands stable and efficient
        tuning strategies, especially in online and continuous learning contexts. Since parameter
        metrics are difficult to capture and do not readily lend themselves to strong heuristics, we
        focus on capturing stateful transitions and propose tailored end-to-end tuners.
      </p>
      <p>
        Navigating complex parameter spaces poses significant challenges for traditional search
        strategies and advanced model-based approaches. Traditional methods (random search, grid
        search) fall short in large parameter spaces, while out-of-box frameworks (e.g., SMBO) become
        expensive when workloads shift. <strong>LITune</strong> offers online, stateful index tuning
        using deep reinforcement learning (DRL), mitigating the instabilities and aimless explorations
        of generic tuning methods.
      </p>
    </div>
    <br>

    <h3 class="subtitle is-4">2.2 System Overview</h3>
    <div class="content has-text-justified">
      <p>
        At the core of <strong>LITune</strong> is a reinforcement learning approach designed to adapt
        to dynamic workloads beyond traditional cost models. We design a Markov Decision Process
        (MDP) framework, with the RL agent interacting with the environment to maximize rewards
        (system performance). <strong>LITune</strong> operates in two main phases:
        <em>Training Stage</em> and <em>Online Tuning Stage</em>. In the Training Stage, we generate
        a pre-trained model that can be deployed and continuously fine-tuned during the Online Tuning
        Stage. A context-aware RL system is used to prevent early terminations and ensure stable,
        high-performance configurations.
      </p>
    </div>

    <!-- LITune System Diagram -->
    <figure class="image" style="margin-top: 20px;">
      <img src="static/images/LITune_Sys.png" alt="LITune System Overview">
      <figcaption style="margin-top: 10px; text-align:center;">
        <strong>Figure:</strong> <em>LITune</em> system diagram illustrating the RL-based
        training and online tuning pipeline.
      </figcaption>
    </figure>



  </div>
</section>

<!-- SECTION 3: Key Features and Experimental Results -->

<section class="section hero">
  <div class="container is-max-desktop">
    <h2 class="title is-3">3. Key Features and Experimental Results</h2>
    <br>
    <h3 class="subtitle is-4">3.1 LITune is Highly Effective</h3>
    <div class="content has-text-justified">
      <p>
        We showcase <strong>LITune</strong>'s end-to-end performance on various workloads. The
        following charts highlight its effectiveness compared to default and other baseline tuning
        methods.
      </p>
    </div>

    <!-- Example performance charts -->
    <figure class="image" style="margin-top: 20px;">
      <img src="static/images/perf_chart.png" alt="Performance Chart">
      <figcaption style="margin-top: 10px; text-align:center;">
        <strong>Figure:</strong> LITune end-to-end runtime performance across multiple workloads.
      </figcaption>
    </figure>

    <figure class="image" style="margin-top: 20px;">
      <img src="static/images/perf_table.png" alt="Performance Table">
      <figcaption style="margin-top: 10px; text-align:center;">
        <strong>Table:</strong> Detailed comparison table of average throughput and latency.
      </figcaption>
    </figure>

    <br>

    <h3 class="subtitle is-4">3.2 Safe and Stable Tuning</h3>
    <div class="content has-text-justified">
      <p>
        Exploring parameter spaces can enhance system performance but also introduces risks, especially
        when parameters significantly impact system reliability. <strong>LITune</strong> addresses
        this with a Safe-RL module, ensuring stable exploration and preventing catastrophic failures.
      </p>
      <p>
        The figure below compares training stability for <em>LITune</em> with and without Safe-RL.
        Without Safe-RL, reward signals exhibit high volatility due to system terminations from
        aggressive parameter exploration. In contrast, <em>LITune</em> with Safe-RL maintains stable
        improvement and achieves better final performance with fewer failures.
      </p>
    </div>

    <!-- Safe RL figure -->
    <figure class="image" style="margin-top: 20px;">
      <img src="static/images/safety.png" alt="Safe and Stable Tuning Figure">
      <figcaption style="margin-top: 10px; text-align:center;">
        <strong>Figure:</strong> (a) Training stability comparison with/without Safe-RL.
        (b) End-to-end runtime performance after tuning on the MIX dataset.
      </figcaption>
    </figure>

    <div class="content has-text-justified" style="margin-top: 20px;">
      <p>
        This stability also translates to better end-to-end performance. On average, <strong>LITune</strong>
        with Safe-RL achieves significantly lower runtime with much less variance, demonstrating that
        safer exploration leads to both better and more reliable tuning outcomes.
      </p>
    </div>
  </div>
</section>


<!-- BibTeX or References -->
<section class="section" id="References and BIBTEX">
  <div class="container is-max-desktop content">
    <h2 class="title">References and Bibtex</h2>
    <p>
      [1] Kraska et al. “The Case for Learned Index Structures.” SIGMOD, 2018.<br>
      [2] Ding et al. “ALEX: An Updatable Adaptive Learned Index.” SIGMOD, 2020.<br>
      [3] Ferragina and Vinciguerra. “PGM-Index: Learning-Compliant Hash Indexes.” 2020.<br>
    </p>

    <pre><code>@article{wang2025new,
  title={A New Paradigm in Tuning Learned Indexes: A Reinforcement Learning Enhanced Approach},
  author={Wang, Taiyi and Liang, Liang and Yang, Guang and Heinis, Thomas and Yoneki, Eiko},
  journal={arXiv preprint arXiv:2502.05001},
  year={2025}
}
</code></pre>
  </div>
</section>

